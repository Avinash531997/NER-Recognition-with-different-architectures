{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\VISHAL SINGH\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Exploring the NER Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_words=[]\n",
    "sentences_tags=[]\n",
    "file = open('NER-Dataset-Train.txt', 'r')\n",
    "lines = file.readlines()\n",
    "temp_sentence_words=[]\n",
    "temp_sentence_tags=[]\n",
    "for line in lines:\n",
    "    if line==\"\\n\":#Sentences ends at every blank line\n",
    "        if len(temp_sentence_words)==0:#If zero length sentence is formed, then ignore\n",
    "            continue\n",
    "        sentences_words.append(temp_sentence_words)\n",
    "        temp_sentence_words=[]\n",
    "        sentences_tags.append(temp_sentence_tags)\n",
    "        temp_sentence_tags=[]\n",
    "        continue\n",
    "    temp=line.split(\"\\t\")#splitting to get the tag and the word\n",
    "    temp[1]=temp[1].split(\"\\n\")[0]\n",
    "\n",
    "    temp_sentence_words.append(temp[0])\n",
    "    temp_sentence_tags.append(temp[1])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Basic',\n",
       " 'Step',\n",
       " 'Before',\n",
       " 'You',\n",
       " 'Even',\n",
       " 'Start',\n",
       " 'Thinking',\n",
       " 'Of',\n",
       " 'Making',\n",
       " 'Your',\n",
       " '...:',\n",
       " 'Keyword',\n",
       " 'research',\n",
       " 'is',\n",
       " 'a',\n",
       " 'well',\n",
       " 'known',\n",
       " 'subject',\n",
       " ',',\n",
       " 'yet',\n",
       " 'so',\n",
       " '...',\n",
       " 'http://bit.ly/9XQgSr']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_words[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tags[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sentences_words\n",
    "Y=sentences_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 900)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1346, 231, 8, 16, 18, 808, 66, 22, 1347, 809]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer = Tokenizer()   #initializing tokenizer\n",
    "word_tokenizer.fit_on_texts(X) \n",
    "X_encoded = word_tokenizer.texts_to_sequences(X) #tokenizing input based on index of every word in vocab set\n",
    "X_encoded[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_tokenizer = Tokenizer()\n",
    "tags_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tags_tokenizer.texts_to_sequences(Y) # tokenizing each tag based on index in tag vocab.\n",
    "Y_encoded[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TAGS=len(tags_tokenizer.word_counts)\n",
    "NUM_TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4542"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE=len(word_tokenizer.word_counts)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Sentences\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in X], bins=100, color=\"blue\")\n",
    "plt.show()\n",
    "MAX_SEQ_LENGTH=max([len(s) for s in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Input Sentences and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1333,  804,   35,    8,  108,  197,   30,  805,   45,  198,   49,\n",
       "       1334,   87,   63,    4,   30,  287, 1335,  584,  379,   95, 1336,\n",
       "        379, 1337,    8,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
    "X_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
    "Y_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-Assigning to X and Y for ease of use\n",
    "X, Y = X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 37, 4)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Compile a LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import SimpleRNN, RNN,SpatialDropout1D,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM=50\n",
    "NUM_TAGS=Y.shape[2]\n",
    "VOCAB_SIZE+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,Y_train,X_test,Y_test):\n",
    "    VALID_SIZE=0.15 #Validation Split Size\n",
    "    #Train - Validation Set Split\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=1)\n",
    "    # total number of tags\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding layer \n",
    "    model.add(Embedding(input_dim     =  VOCAB_SIZE,         \n",
    "                            output_dim    =  EMBED_DIM,          \n",
    "                            input_length  =  MAX_SEQ_LENGTH,              \n",
    "                            trainable     =  True                     # True - update the embeddings while training\n",
    "    ))\n",
    "\n",
    "    \n",
    "    #Adding RNN Layer \n",
    "    model.add(SimpleRNN(64, \n",
    "                  return_sequences=True  # True to return whole sequence output \n",
    "    ))\n",
    "    model.add(Dropout(0.2)) # Adding dropout to avoid overfitting\n",
    "\n",
    "    # Adding TimeDistributed layer - Softmax output based on number of classes or tags\n",
    "    model.add(TimeDistributed(Dense(NUM_TAGS, activation='softmax')))\n",
    "\n",
    "    #Compiling model\n",
    "    model.compile(loss      =  'categorical_crossentropy',\n",
    "                      optimizer =  'adam',\n",
    "                      metrics   =  ['acc', Precision(), Recall()])\n",
    "    \n",
    "    # model summary\n",
    "    model.summary()\n",
    "    #Hyper-parameters for the model\n",
    "    epochs=10\n",
    "    batch_size=128\n",
    "    \n",
    "\n",
    "    #Fitting Model\n",
    "    rnn_training = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validation, Y_validation))\n",
    "    #Model Evaluation\n",
    "    loss, accuracy, precision, recall = model.evaluate(X_train, Y_train, verbose = 1)\n",
    "    print(\"Loss: {0},\\nTrain Accuracy: {1}\".format(loss, accuracy*100))\n",
    "    print(\"Precision: {0},\\nRecall: {1}\".format(precision, recall))\n",
    "    print(\" \"*50)\n",
    "    loss, accuracy, precision, recall = model.evaluate(X_test, Y_test, verbose = 1)\n",
    "    print(\"Loss: {0},\\nTest Accuracy: {1}\".format(loss, accuracy*100))\n",
    "    print(\"Precision: {0},\\nRecall: {1}\".format(precision, recall))\n",
    "    Y_pred=model.predict(X_test)\n",
    "    return model,Y_pred,Y_test,accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "                        Cross Validation - 1 iteration\n",
      "****************************************************************************************************\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 37, 50)            227150    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 37, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 37, 4)             260       \n",
      "=================================================================\n",
      "Total params: 234,770\n",
      "Trainable params: 234,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 239ms/step - loss: 1.3536 - acc: 0.3445 - precision: 0.3333 - recall: 1.4721e-05 - val_loss: 1.1415 - val_acc: 0.8081 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0538 - acc: 0.7919 - precision: 0.9765 - recall: 0.1181 - val_loss: 0.7881 - val_acc: 0.8471 - val_precision: 0.9164 - val_recall: 0.4525\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7251 - acc: 0.8644 - precision: 0.9269 - recall: 0.5519 - val_loss: 0.6020 - val_acc: 0.8493 - val_precision: 0.8571 - val_recall: 0.6754\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5416 - acc: 0.8798 - precision: 0.8952 - recall: 0.7194 - val_loss: 0.5244 - val_acc: 0.8576 - val_precision: 0.8578 - val_recall: 0.7365\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4241 - acc: 0.9087 - precision: 0.9159 - recall: 0.7950 - val_loss: 0.4734 - val_acc: 0.8706 - val_precision: 0.8702 - val_recall: 0.7720\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3702 - acc: 0.9222 - precision: 0.9281 - recall: 0.8292 - val_loss: 0.4554 - val_acc: 0.8756 - val_precision: 0.8743 - val_recall: 0.7885\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3156 - acc: 0.9397 - precision: 0.9443 - recall: 0.8591 - val_loss: 0.4571 - val_acc: 0.8759 - val_precision: 0.8732 - val_recall: 0.7993\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2818 - acc: 0.9480 - precision: 0.9531 - recall: 0.8786 - val_loss: 0.4734 - val_acc: 0.8741 - val_precision: 0.8724 - val_recall: 0.8073\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2609 - acc: 0.9531 - precision: 0.9565 - recall: 0.8899 - val_loss: 0.4918 - val_acc: 0.8729 - val_precision: 0.8718 - val_recall: 0.8101\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2441 - acc: 0.9566 - precision: 0.9603 - recall: 0.8994 - val_loss: 0.5282 - val_acc: 0.8696 - val_precision: 0.8672 - val_recall: 0.8091\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2270 - acc: 0.9623 - precision: 0.9660 - recall: 0.9111\n",
      "Loss: 0.22698338329792023,\n",
      "Train Accuracy: 96.22858166694641\n",
      "Precision: 0.9660080671310425,\n",
      "Recall: 0.9111464619636536\n",
      "                                                  \n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5492 - acc: 0.8632 - precision: 0.8632 - recall: 0.8056\n",
      "Loss: 0.5492053627967834,\n",
      "Test Accuracy: 86.32132411003113\n",
      "Precision: 0.8632341027259827,\n",
      "Recall: 0.8055555820465088\n",
      "****************************************************************************************************\n",
      "                        Cross Validation - 2 iteration\n",
      "****************************************************************************************************\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 37, 50)            227150    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 37, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 37, 4)             260       \n",
      "=================================================================\n",
      "Total params: 234,770\n",
      "Trainable params: 234,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 151ms/step - loss: 1.3290 - acc: 0.3671 - precision_1: 0.5000 - recall_1: 0.0085 - val_loss: 1.0320 - val_acc: 0.5473 - val_precision_1: 0.9699 - val_recall_1: 0.3706\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.9862 - acc: 0.5608 - precision_1: 0.8501 - recall_1: 0.3823 - val_loss: 0.8018 - val_acc: 0.6879 - val_precision_1: 0.8120 - val_recall_1: 0.4474\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.7673 - acc: 0.7991 - precision_1: 0.9055 - recall_1: 0.4837 - val_loss: 0.6143 - val_acc: 0.8734 - val_precision_1: 0.9174 - val_recall_1: 0.6196\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5781 - acc: 0.8855 - precision_1: 0.9210 - recall_1: 0.6707 - val_loss: 0.4995 - val_acc: 0.8801 - val_precision_1: 0.8922 - val_recall_1: 0.7292\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4510 - acc: 0.9144 - precision_1: 0.9290 - recall_1: 0.7819 - val_loss: 0.4358 - val_acc: 0.8904 - val_precision_1: 0.9003 - val_recall_1: 0.7820\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3864 - acc: 0.9229 - precision_1: 0.9317 - recall_1: 0.8230 - val_loss: 0.4260 - val_acc: 0.8831 - val_precision_1: 0.8856 - val_recall_1: 0.7945\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3394 - acc: 0.9307 - precision_1: 0.9373 - recall_1: 0.8499 - val_loss: 0.4475 - val_acc: 0.8751 - val_precision_1: 0.8769 - val_recall_1: 0.8003\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3057 - acc: 0.9354 - precision_1: 0.9423 - recall_1: 0.8694 - val_loss: 0.4682 - val_acc: 0.8704 - val_precision_1: 0.8713 - val_recall_1: 0.8051\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2850 - acc: 0.9435 - precision_1: 0.9488 - recall_1: 0.8844 - val_loss: 0.4322 - val_acc: 0.8821 - val_precision_1: 0.8852 - val_recall_1: 0.8236\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2571 - acc: 0.9508 - precision_1: 0.9563 - recall_1: 0.8965 - val_loss: 0.3963 - val_acc: 0.8946 - val_precision_1: 0.8983 - val_recall_1: 0.8398\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2441 - acc: 0.9491 - precision_1: 0.9543 - recall_1: 0.8998\n",
      "Loss: 0.24405759572982788,\n",
      "Train Accuracy: 94.9125587940216\n",
      "Precision: 0.954289972782135,\n",
      "Recall: 0.8998410105705261\n",
      "                                                  \n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3332 - acc: 0.9144 - precision_1: 0.9165 - recall_1: 0.8584\n",
      "Loss: 0.33324429392814636,\n",
      "Test Accuracy: 91.44144058227539\n",
      "Precision: 0.9164796471595764,\n",
      "Recall: 0.8584083914756775\n",
      "****************************************************************************************************\n",
      "                        Cross Validation - 3 iteration\n",
      "****************************************************************************************************\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 37, 50)            227150    \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 37, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 37, 4)             260       \n",
      "=================================================================\n",
      "Total params: 234,770\n",
      "Trainable params: 234,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 133ms/step - loss: 1.3046 - acc: 0.3303 - precision_2: 0.5380 - recall_2: 0.0192 - val_loss: 0.9167 - val_acc: 0.5923 - val_precision_2: 0.8344 - val_recall_2: 0.4412\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.9113 - acc: 0.5705 - precision_2: 0.7321 - recall_2: 0.4208 - val_loss: 0.8093 - val_acc: 0.5748 - val_precision_2: 0.6556 - val_recall_2: 0.4935\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.8333 - acc: 0.5898 - precision_2: 0.6364 - recall_2: 0.4657 - val_loss: 0.7551 - val_acc: 0.7200 - val_precision_2: 0.7467 - val_recall_2: 0.5230\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.7636 - acc: 0.7161 - precision_2: 0.7325 - recall_2: 0.5401 - val_loss: 0.6722 - val_acc: 0.7920 - val_precision_2: 0.7832 - val_recall_2: 0.6111\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.6716 - acc: 0.7943 - precision_2: 0.7938 - recall_2: 0.6319 - val_loss: 0.5404 - val_acc: 0.9219 - val_precision_2: 0.9356 - val_recall_2: 0.7848\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.5345 - acc: 0.8947 - precision_2: 0.9022 - recall_2: 0.7602 - val_loss: 0.4262 - val_acc: 0.9192 - val_precision_2: 0.9250 - val_recall_2: 0.8086\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4142 - acc: 0.9180 - precision_2: 0.9215 - recall_2: 0.81 - 0s 38ms/step - loss: 0.4091 - acc: 0.9196 - precision_2: 0.9231 - recall_2: 0.8195 - val_loss: 0.3622 - val_acc: 0.9227 - val_precision_2: 0.9271 - val_recall_2: 0.8373\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3460 - acc: 0.9291 - precision_2: 0.9334 - recall_2: 0.8521 - val_loss: 0.3442 - val_acc: 0.9157 - val_precision_2: 0.9210 - val_recall_2: 0.8466\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3042 - acc: 0.9334 - precision_2: 0.9365 - recall_2: 0.8692 - val_loss: 0.3202 - val_acc: 0.9197 - val_precision_2: 0.9249 - val_recall_2: 0.8599\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2701 - acc: 0.9427 - precision_2: 0.9458 - recall_2: 0.8868 - val_loss: 0.3178 - val_acc: 0.9194 - val_precision_2: 0.9236 - val_recall_2: 0.8651\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2427 - acc: 0.9478 - precision_2: 0.9510 - recall_2: 0.8971\n",
      "Loss: 0.2427498996257782,\n",
      "Train Accuracy: 94.7844922542572\n",
      "Precision: 0.951032280921936,\n",
      "Recall: 0.8971471190452576\n",
      "                                                  \n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4234 - acc: 0.8890 - precision_2: 0.8893 - recall_2: 0.8356\n",
      "Loss: 0.4233543276786804,\n",
      "Test Accuracy: 88.90390396118164\n",
      "Precision: 0.8892617225646973,\n",
      "Recall: 0.8355855941772461\n",
      "****************************************************************************************************\n",
      "                        Cross Validation - 4 iteration\n",
      "****************************************************************************************************\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 37, 50)            227150    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 37, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 37, 4)             260       \n",
      "=================================================================\n",
      "Total params: 234,770\n",
      "Trainable params: 234,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 130ms/step - loss: 1.2260 - acc: 0.4906 - precision_3: 0.8291 - recall_3: 0.0606 - val_loss: 0.9215 - val_acc: 0.6211 - val_precision_3: 0.8973 - val_recall_3: 0.4284\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8656 - acc: 0.6692 - precision_3: 0.8826 - recall_3: 0.4332 - val_loss: 0.6999 - val_acc: 0.8471 - val_precision_3: 0.9347 - val_recall_3: 0.5556\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6306 - acc: 0.8664 - precision_3: 0.9230 - recall_3: 0.6066 - val_loss: 0.5570 - val_acc: 0.8614 - val_precision_3: 0.8796 - val_recall_3: 0.6912\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4938 - acc: 0.8955 - precision_3: 0.9065 - recall_3: 0.7353 - val_loss: 0.5212 - val_acc: 0.8556 - val_precision_3: 0.8600 - val_recall_3: 0.7272\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4239 - acc: 0.9020 - precision_3: 0.9066 - recall_3: 0.7839 - val_loss: 0.4493 - val_acc: 0.8804 - val_precision_3: 0.8879 - val_recall_3: 0.7790\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3624 - acc: 0.9210 - precision_3: 0.9262 - recall_3: 0.8239 - val_loss: 0.4275 - val_acc: 0.8884 - val_precision_3: 0.8936 - val_recall_3: 0.8008\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3226 - acc: 0.9329 - precision_3: 0.9379 - recall_3: 0.8514 - val_loss: 0.4208 - val_acc: 0.8861 - val_precision_3: 0.8896 - val_recall_3: 0.8086\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2840 - acc: 0.9455 - precision_3: 0.9503 - recall_3: 0.8725 - val_loss: 0.4092 - val_acc: 0.8874 - val_precision_3: 0.8926 - val_recall_3: 0.8218\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2680 - acc: 0.9468 - precision_3: 0.9505 - recall_3: 0.8833 - val_loss: 0.3948 - val_acc: 0.8924 - val_precision_3: 0.8971 - val_recall_3: 0.8313\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2454 - acc: 0.9503 - precision_3: 0.9538 - recall_3: 0.8936 - val_loss: 0.3986 - val_acc: 0.8886 - val_precision_3: 0.8937 - val_recall_3: 0.8311\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2259 - acc: 0.9541 - precision_3: 0.9568 - recall_3: 0.9018\n",
      "Loss: 0.22589722275733948,\n",
      "Train Accuracy: 95.40717005729675\n",
      "Precision: 0.9567559957504272,\n",
      "Recall: 0.9018282890319824\n",
      "                                                  \n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3625 - acc: 0.8998 - precision_3: 0.8996 - recall_3: 0.8408\n",
      "Loss: 0.362531840801239,\n",
      "Test Accuracy: 89.98498320579529\n",
      "Precision: 0.8995984196662903,\n",
      "Recall: 0.8408408164978027\n",
      "****************************************************************************************************\n",
      "                        Cross Validation - 5 iteration\n",
      "****************************************************************************************************\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 37, 50)            227150    \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 37, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 37, 4)             260       \n",
      "=================================================================\n",
      "Total params: 234,770\n",
      "Trainable params: 234,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 138ms/step - loss: 1.3810 - acc: 0.2510 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.1686 - val_acc: 0.6582 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.0903 - acc: 0.6689 - precision_4: 0.9090 - recall_4: 0.0844 - val_loss: 0.9133 - val_acc: 0.7155 - val_precision_4: 0.7701 - val_recall_4: 0.4124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.8728 - acc: 0.7091 - precision_4: 0.7373 - recall_4: 0.3529 - val_loss: 0.7623 - val_acc: 0.7625 - val_precision_4: 0.7493 - val_recall_4: 0.5638\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6991 - acc: 0.8014 - precision_4: 0.8070 - recall_4: 0.6099 - val_loss: 0.6194 - val_acc: 0.8193 - val_precision_4: 0.8165 - val_recall_4: 0.6882\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5626 - acc: 0.8490 - precision_4: 0.8491 - recall_4: 0.7253 - val_loss: 0.5751 - val_acc: 0.8351 - val_precision_4: 0.8315 - val_recall_4: 0.7297\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4736 - acc: 0.8846 - precision_4: 0.8836 - recall_4: 0.7794 - val_loss: 0.5286 - val_acc: 0.8483 - val_precision_4: 0.8451 - val_recall_4: 0.7535\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4001 - acc: 0.9095 - precision_4: 0.9112 - recall_4: 0.8182 - val_loss: 0.5137 - val_acc: 0.8509 - val_precision_4: 0.8467 - val_recall_4: 0.7658\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3526 - acc: 0.9241 - precision_4: 0.9274 - recall_4: 0.8430 - val_loss: 0.5356 - val_acc: 0.8448 - val_precision_4: 0.8406 - val_recall_4: 0.7680\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3195 - acc: 0.9345 - precision_4: 0.9400 - recall_4: 0.8622 - val_loss: 0.4814 - val_acc: 0.8639 - val_precision_4: 0.8611 - val_recall_4: 0.7925\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.2887 - acc: 0.9472 - precision_4: 0.9512 - recall_4: 0.8824 - val_loss: 0.4829 - val_acc: 0.8656 - val_precision_4: 0.8631 - val_recall_4: 0.7985\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2612 - acc: 0.9522 - precision_4: 0.9561 - recall_4: 0.8923\n",
      "Loss: 0.261185884475708,\n",
      "Train Accuracy: 95.22169232368469\n",
      "Precision: 0.9560897350311279,\n",
      "Recall: 0.8923335075378418\n",
      "                                                  \n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4587 - acc: 0.8760 - precision_4: 0.8717 - recall_4: 0.8102\n",
      "Loss: 0.45872175693511963,\n",
      "Test Accuracy: 87.59759664535522\n",
      "Precision: 0.8717285990715027,\n",
      "Recall: 0.8102102279663086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#Shuffling and splitting into 5 different sets for cross validation\n",
    "cv = ShuffleSplit(n_splits=5, test_size=.20, random_state=1)\n",
    "cv_scores=[0]*5\n",
    "itr=0\n",
    "prec=[0]*5\n",
    "rec=[0]*5\n",
    "#Initializing\n",
    "best_pred_set=None\n",
    "best_test_set=None\n",
    "best_accuracy=0 \n",
    "best_precision=0\n",
    "best_recall=0\n",
    "#For each split creating and evaluating model\n",
    "for train_idx,test_idx in cv.split(X):\n",
    "    itr+=1\n",
    "    print(\"*\"*100)\n",
    "    print(\"                        Cross Validation - {} iteration\".format(itr))\n",
    "    print(\"*\"*100)\n",
    "    model,Pred_Set,Test_Set,cv_scores[itr-1],prec[itr-1],rec[itr-1]=evaluate_model(X[train_idx],Y[train_idx]\n",
    "                                                            ,X[test_idx],Y[test_idx])\n",
    "    if cv_scores[itr-1]>best_accuracy:\n",
    "        best_accuracy=cv_scores[itr-1]\n",
    "        best_precision=prec[itr-1]\n",
    "        best_recall=rec[itr-1]\n",
    "        best_test_set=Test_Set\n",
    "        best_pred_set=Pred_Set\n",
    "        best_model=model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the best model among the 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy is given as 0.8884984970092773\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Test Accuracy is given as {}\".format(sum(cv_scores)/len(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Accuracy among all the folds is given as 0.9144144058227539\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Test Accuracy among all the folds is given as {}\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracies for the 5 folds are given as :\n",
      "0.8632132411003113 0.9144144058227539 0.8890390396118164 0.8998498320579529 0.8759759664535522\n"
     ]
    }
   ],
   "source": [
    "print(\"The Accuracies for the 5 folds are given as :\")\n",
    "print(*cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision : 0.8880604982376099, Average Recall : 0.8301201224327087\n"
     ]
    }
   ],
   "source": [
    "print(\"Average precision : {}, Average Recall : {}\".format(sum(prec)/5,sum(rec)/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(p,r):\n",
    "    return 2*(p*r)/(p+r)\n",
    "\n",
    "best_fscore=f_score(best_precision,best_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Precision : 0.9164796471595764, Recall : 0.8584083914756775 and F-Score : 0.8864940239761467\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model Precision : {}, Recall : {} and F-Score : {}\".format(best_precision,\n",
    "                                                                       best_recall,best_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tags_tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding the predicted tags in the best_pred_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pred(Y):\n",
    "    #Defining an empty matrix of zeros of shape of best_pred_set\n",
    "    out = np.zeros(Y.shape)\n",
    "    #Finding the tag index for each sequence which has the highest probablity value \n",
    "    idx = Y.argmax(axis=-1)\n",
    "    #Setting that value to 1 and rest to 0\n",
    "    out[np.arange(Y.shape[0])[:,None],np.arange(Y.shape[1]),idx] = 1\n",
    "    pred=np.argmax(out, axis=-1)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the index having the max value among the 21 tag values for a certain sequence\n",
    "best_pred=decode_pred(best_pred_set)\n",
    "best_test=np.argmax(best_test_set,axis=2)\n",
    "#Actual Tags(Encoded) for the 2nd sequence in Test Set\n",
    "best_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted Tags(Encoded) for the 2nd sequence in Test Set\n",
    "best_pred[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-wise accuracy for the different tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive=[0]*(NUM_TAGS)\n",
    "actual_count=[0]*(NUM_TAGS)\n",
    "for i in range(best_test.shape[0]):\n",
    "    for j in range(best_test.shape[1]):\n",
    "        if best_test[i][j]==0: #Ignore if its 0 as it is present due to padding\n",
    "            continue\n",
    "        #if both are equal then increment count by 1 for true positive case\n",
    "        if best_test[i][j]==best_pred[i][j]:\n",
    "            true_positive[best_test[i][j]]+=1\n",
    "        actual_count[best_test[i][j]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 3210, 100, 57], [0, 2978, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_count,true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "             Class-Wise Accuracies for different classes are \n",
      "****************************************************************************************************\n",
      "Accuracy of Tag - Class o is : 92.77258566978193 %\n",
      "Accuracy of Tag - Class b is : 0.0 %\n",
      "Accuracy of Tag - Class i is : 0.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*100)\n",
    "print(\"             Class-Wise Accuracies for different classes are \")\n",
    "print(\"*\"*100)\n",
    "class_accuracies=[]\n",
    "for i in range(1,NUM_TAGS):\n",
    "    if actual_count[i]!=0:\n",
    "        class_accuracies.append((true_positive[i]/actual_count[i])*100)\n",
    "        print(\"Accuracy of Tag - Class {} is : {} %\".format(reverse_word_map.get(i),(class_accuracies[i-1])))\n",
    "    else:\n",
    "        class_accuracies.append(0)\n",
    "        print(\"Accuracy of Tag - Class {} is : 0.0 % \".format(reverse_word_map.get(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (14, 5)) \n",
    "# creating the bar plot \n",
    "category_list=[str(reverse_word_map.get(i)) for i in range(1,NUM_TAGS)]\n",
    "plt.bar(category_list, class_accuracies, color ='blue',  \n",
    "        width = 0.4) \n",
    "  \n",
    "plt.xlabel(\"Tag - Classes\") \n",
    "plt.ylabel(\"Percentage Accuracy\") \n",
    "plt.title(\"Different Tag - Classes Accuracy\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_words=[]\n",
    "file = open('NER-Dataset--TestSet.txt', 'r')\n",
    "lines = file.readlines()\n",
    "temp_sentence_words=[]\n",
    "for line in lines:\n",
    "    if line==\"\\n\":#Blank line represents end of sentence\n",
    "        test_sentences_words.append(temp_sentence_words)\n",
    "        temp_sentence_words=[]\n",
    "        continue\n",
    "    temp=line.split(\"\\n\")[0]\n",
    "    temp_sentence_words.append(temp)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@SammieLynnsMom',\n",
       " '@tg1.781',\n",
       " 'they',\n",
       " 'will',\n",
       " 'be',\n",
       " 'all',\n",
       " 'done',\n",
       " 'by',\n",
       " 'Sunday',\n",
       " 'trust',\n",
       " 'me',\n",
       " '*wink*']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test=word_tokenizer.texts_to_sequences(test_sentences_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test_padded=pad_sequences(X_Test, maxlen=MAX_SEQ_LENGTH, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Predicted_Set=best_model.predict(X_Test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Predicted=decode_pred(Y_Predicted_Set)\n",
    "Y_Predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "\n",
    "# Creating texts \n",
    "Y_Pred_Labels = list(map(sequence_to_text, Y_Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred_Labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
